# Synth-MIA: A Testbed for Auditing Privacy Leakage in Tabular Data Synthesis

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)  
[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)  



**Synth_MIA** is an open-source library for performing Membership Inference Attacks (MIA) on generative models. It provides a suite of tools and methodologies to evaluate privacy risks in modern generative machine learning systems. 

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Citation](#citation)
- [License](#license)

## Installation

You can install `synth_mia` directly from the GitHub repository using `pip`:

```sh
pip install .
```



## Usage

### Running Membership Inference Attacks

The following example demonstrates how to use `synth_mia` to run multiple membership inference attacks on your data. In this example, it is assumed that your data has already been split into the following four CSV files:

- **mem.csv**: Data points that were used during model training (members).
- **non_mem.csv**: Data points that were not used during training (non-members).
- **ref.csv**: Reference data for baseline comparison.
- **synth.csv**: Synthetic data generated by your model.

Below is an example script illustrating the process:

```python
import pandas as pd
import numpy as np
from synth_mia.attackers import *
from synth_mia import utils, evaluation

# Load the data used in the training of the model, the test set, and the final synthetic data
train_set = pd.read_csv('../example_data/insurance/train_set.csv')
test_set = pd.read_csv('../example_data/insurance/holdout_set.csv')
synth_set = pd.read_csv('../example_data/insurance/bayesian_network_synth_250.csv')

# Split the test set into a non-member set and a reference set
non_member_set, reference_set = utils.create_random_equal_dfs(test_set, 250, num_dfs=2, seed=42)

# Preprocess dataframes into encoded numpy arrays
prep = utils.TabularPreprocessor(fit_target='synth', categorical_encoding='one-hot', numeric_encoding='standard')

# Fit on chosen target (ref is optional if fit_target='synth')
prep.fit(train_set, non_member_set, synth_set)

# Transform all datasets
mem, non_mem, synth, ref, transformer = prep.transform(train_set, non_member_set, synth_set)

# Create instances of your attackers
att1 = DCR()

# Run attacks and evaluate results
results = {}
attackers = [att1]

for attacker in attackers:
    # Run the attack
    true_labels, scores = attacker.attack(mem, non_mem, synth, ref)
    
    # Evaluate the attack
    eval_results = attacker.eval(true_labels, scores, metrics=['roc'])
    
    # Store results
    results[attacker.name] = eval_results

# Print results
pd.DataFrame(results).T
```

## License

This project is licensed under the MIT License. 

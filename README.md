# Synth-MIA: A Testbed for Auditing Privacy Leakage in Tabular Data Synthesis

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)  
[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)  


![image](assets/system.png)


**Synth_MIA** is an open-source library for performing Membership Inference Attacks (MIA) on generative models. It provides a suite of tools and methodologies to evaluate privacy risks in modern generative machine learning systems. 

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Citation](#citation)
- [License](#license)

## Installation

You can install `synth_mia` directly from the GitHub repository using `pip`:

```sh
pip install .
```



## Usage

### Running Membership Inference Attacks

The following example demonstrates how to use `synth_mia` to run multiple membership inference attacks on your data. In this example, it is assumed that your data has already been split into the following four CSV files:

- **mem.csv**: Data points that were used during model training (members).
- **non_mem.csv**: Data points that were not used during training (non-members).
- **ref.csv**: Reference data for baseline comparison.
- **synth.csv**: Synthetic data generated by your model.

Below is an example script illustrating the process:

```python
import pandas as pd
import numpy as np
from synth_mia import GenLRA, DCR, MC, LOGAN, DCRDiff, DPI, DOMIAS, DensityEstimate, LocalNeighborhood, Classifier

# Load the datasets (update the paths as needed)
mem = pd.read_csv('example_data/housing/mem.csv').values
non_mem = pd.read_csv('example_data/housing/non_mem.csv').values
ref = pd.read_csv('example_data/housing/ref.csv').values
synth = pd.read_csv('example_data/housing/synth.csv').values

# Initialize instances of various attackers.
# You can adjust hyperparameters as required.
att1 = GenLRA(hyper_parameters={'k_nearest': 200})
att2 = DCR()
att3 = DPI()
att4 = LOGAN()
att5 = DCRDiff()
att6 = DOMIAS()
att7 = MC()
att8 = DensityEstimate(hyper_parameters={"estimation_method": "kde"})
att9 = LocalNeighborhood()
att10 = classifier()

# List of all attacker instances
attackers = [att1, att2, att3, att4, att5, att6, att7, att8, att9, att10]

# Dictionary to store evaluation results for each attacker
results = {}

for attacker in attackers:
    # Execute the attack.
    # The attack method returns a tuple containing:
    #   - scores: Attack confidence scores for each sample.
    #   - true_labels: Ground truth membership labels.
    scores, true_labels = attacker.attack(mem, non_mem, synth, ref)
    
    # Evaluate the attack using the ROC metric.
    eval_results = attacker.eval(scores, true_labels, metrics=['roc'])
    
    # Save the evaluation results with the attacker name as key.
    results[attacker.name] = eval_results

# Display the results in a transposed DataFrame for easier interpretation.
print(pd.DataFrame(results).T)
```



## License

This project is licensed under the MIT License. 
# Synth-MIA
